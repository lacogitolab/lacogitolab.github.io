---
layout: post
title: "Scaling of Neurosymbolic AI"
date: 2025-11-15
author: "Xiaming Chen"
header-img: "img/post-bg-universe.jpg"
tags: ["Neuro-symbolic", "Data efficiency", "Scaling computation"]
---

Artificial neural networks (ANN), especially deep learning, illustrate the enormous
capability of modeling complex patterns in an end-to-end manner. Its iconic
architecture — the Transformer — has extended deep learning applications from
narrow academic domains to pervasive practical fields, both commmercial and
scientific. This success is not only attributed to internet-scale training data
and commercially poured computing resources, but also to the efficiently and
deeply scalable design of the Transformer’s attention architecture. Three
scaling factors — data, computing, and architecture — together establish the
foundational pillars of deep learning’s success.

However, there is a transparent wall that blocks the march of deep learning
toward artificial general intelligence — or whatever buzzword people use to
fuel their futuristic imagination. This wall is built from several kinds of
bricks: *data depletion*, *weak interpretability*, *non-explorable reasoning*, and
*the incapability of continual learning*.
